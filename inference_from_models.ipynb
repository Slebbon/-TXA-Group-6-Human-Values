{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r w2v_model\n",
    "# from word2vec.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r doc2vec_final\n",
    "# from doc2vec.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r lda\n",
    "# from nltk_coll_topic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r lda_vectorizer\n",
    "# from nltk_coll_topic.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we try to infer labels from premises' examples written by us. We will use the lstm model trained on word2vec and the cnn with binary cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    # set lowercase\n",
    "    processed_text = [token.text.lower()for token in doc]\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_preprocess(example, model):\n",
    "    ex_tok = preprocess_text(example)\n",
    "    # create the vectors from the w2v model\n",
    "    ex_vectors = []\n",
    "\n",
    "    for word in ex_tok:\n",
    "        if word in w2v_model.wv:\n",
    "            ex_vectors.append(w2v_model.wv[word])\n",
    "        else:\n",
    "            ex_vectors.append(np.zeros(150)) #if the word is not in the model i append an array of zeros equal to the embeddings dimension, that is 150\n",
    "    print(len(ex_vectors[0]))\n",
    "        \n",
    "    return ex_vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2v_topic_preprocess(example, d2v_model, topic_model, topic_vectorizer):\n",
    "\n",
    "    # first we extract the topics\n",
    "    list_example = [example]\n",
    "    ex_tf = topic_vectorizer.transform(list_example)\n",
    "    ex_topics = topic_model.transform(ex_tf)\n",
    "    ex_topics = np.array([top for top in ex_topics[0]])\n",
    "\n",
    "    # we then extract the d2v vectors\n",
    "    ex_tok = preprocess_text(example)\n",
    "    ex_d2v = d2v_model.infer_vector(ex_tok)\n",
    "\n",
    "    # we now concatenate them\n",
    "    ex_d2v_topic_vec = np.array(np.concatenate((ex_topics, ex_d2v), axis = 0))\n",
    "    \n",
    "    return ex_d2v_topic_vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "# load the model\n",
    "lstm_model = load_model('lstm_model.h5')\n",
    "cnn_bce_model = load_model(\"cnn_bce_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r input\n",
    "# from undersampling.ipynb, a list of vectors obtained by concatenating for each document its doc2vec vector and a vector with the topic modeling probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we fit the scaler for the cnn on the training set\n",
    "X_train = np.asarray(input)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference(example, model_type):\n",
    "\n",
    "    if model_type == \"lstm\":\n",
    "        ex_vectors = w2v_preprocess(example, w2v_model)\n",
    "        ex_vectors = np.array(ex_vectors)\n",
    "        # setting max_len and emb_len from the training set\n",
    "        max_len = 163\n",
    "        emb_len = 150\n",
    "        # check if padding is needed\n",
    "        if ex_vectors.shape[0] < max_len:\n",
    "            padding = ((0, max_len - ex_vectors.shape[0]), (0, 0))\n",
    "            X_ex = np.pad(ex_vectors, padding, mode='constant')\n",
    "        else:\n",
    "            X_ex = ex_vectors\n",
    "        # reshaping to accomodate the lstm input size\n",
    "        X_ex = X_ex.reshape((-1, max_len, emb_len))\n",
    "        y_pred = lstm_model.predict(X_ex)\n",
    "\n",
    "    elif model_type == \"cnn\":\n",
    "        ex_vectors = d2v_topic_preprocess(example, doc2vec_final, lda, lda_vectorizer)\n",
    "        X_ex = ex_vectors.reshape(1, -1)\n",
    "        X_ex = scaler.transform(X_ex)\n",
    "        # Reshape 'X_ex' to add an extra dimension\n",
    "        X_ex = X_ex.reshape((1, 1, X_ex.shape[1]))\n",
    "        y_pred = cnn_bce_model.predict(X_ex)\n",
    "\n",
    "    # we now turn the predictions in binary labels\n",
    "    threshold = 0.5\n",
    "    y_pred_binary = (y_pred > threshold).astype(int)\n",
    "    return y_pred_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "150\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[1 1 1 1]] [[1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "x = \"Contraception is wrong, since it's against what is written in the Bible\"\n",
    "y = \"Contraception is good because women should be free to do what they want with their bodies\"\n",
    "print(get_inference(x, model_type=\"lstm\"), get_inference(y, model_type=\"lstm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
